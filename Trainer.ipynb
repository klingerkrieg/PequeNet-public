{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12db7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from util import *\n",
    "import pandas as pd \n",
    "from datetime import timedelta\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import numpy as np\n",
    "\n",
    "#pip install XlsxWriter\n",
    "#jupyter nbconvert --to script Trainer.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe37cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, mode='max', delta=0.0):\n",
    "        self.patience = patience\n",
    "        self.mode = mode\n",
    "        self.delta = delta\n",
    "        self.best_score = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "        if self.mode == 'min':\n",
    "            self.sign = 1\n",
    "        else:  # 'max'\n",
    "            self.sign = -1\n",
    "\n",
    "    def step(self, score):\n",
    "        score = self.sign * score  # transforma max em min se necessário\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "        elif score > self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ef4642",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_segmentation_metrics(preds, targets, num_classes, eps=1e-6):\n",
    "    preds = preds.view(-1).cpu()\n",
    "    targets = targets.view(-1).cpu()\n",
    "\n",
    "    dice_total          = 0.0\n",
    "    miou_total          = 0.0\n",
    "    iou_valid_classes   = 0\n",
    "    precision_per_class = []\n",
    "    recall_per_class    = []\n",
    "\n",
    "    classes_to_eval = [1] if num_classes == 1 else range(num_classes)\n",
    "\n",
    "    for cls in classes_to_eval:\n",
    "        pred_mask = (preds == cls)\n",
    "        target_mask = (targets == cls)\n",
    "\n",
    "        intersection = (pred_mask & target_mask).sum().float()\n",
    "        pred_sum = pred_mask.sum().float()\n",
    "        target_sum = target_mask.sum().float()\n",
    "        union = pred_sum + target_sum\n",
    "\n",
    "        # Dice\n",
    "        if union > 0:\n",
    "            dice = (2.0 * intersection + eps) / (union + eps)\n",
    "            dice_total += dice.item()\n",
    "\n",
    "        # IoU\n",
    "        union_iou = (pred_mask | target_mask).sum().float()\n",
    "        if union_iou > 0:\n",
    "            iou = (intersection + eps) / (union_iou + eps)\n",
    "            miou_total += iou.item()\n",
    "            iou_valid_classes += 1\n",
    "\n",
    "        # Precision, Recall\n",
    "        tp = intersection.item()\n",
    "        fp = (pred_mask & ~target_mask).sum().float().item()\n",
    "        fn = (~pred_mask & target_mask).sum().float().item()\n",
    "\n",
    "        if (tp + fp + fn) > 0:\n",
    "            precision = tp / (tp + fp + eps)\n",
    "            recall = tp / (tp + fn + eps)\n",
    "\n",
    "            precision_per_class.append(precision)\n",
    "            recall_per_class.append(recall)\n",
    "\n",
    "    mean_dice = dice_total / len(classes_to_eval)\n",
    "    mean_iou = miou_total / iou_valid_classes if iou_valid_classes > 0 else 0.0\n",
    "    mean_precision = np.mean(precision_per_class) if precision_per_class else 0.0\n",
    "    mean_recall = np.mean(recall_per_class) if recall_per_class else 0.0\n",
    "    q = mean_iou * mean_dice\n",
    "\n",
    "    #DICE = F1\n",
    "    return mean_dice, mean_iou, mean_precision, mean_recall, q\n",
    "\n",
    "\n",
    "# faz o cálculo imagem por imagem e depois tira a média.\n",
    "def compute_iou(preds, masks, num_classes=1, eps=1e-6):\n",
    "    iou_per_class = [ [] for _ in range(num_classes) ]  # lista de listas\n",
    "\n",
    "    batch_size = preds.size(0)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        pred = preds[i]\n",
    "        mask = masks[i]\n",
    "\n",
    "        for cls in range(num_classes):\n",
    "            pred_cls = (pred == cls).float()\n",
    "            mask_cls = (mask == cls).float()\n",
    "\n",
    "            if mask_cls.sum() == 0:\n",
    "                continue  # não avalia classe ausente no ground truth\n",
    "\n",
    "            intersection = (pred_cls * mask_cls).sum()\n",
    "            union = ((pred_cls + mask_cls) > 0).float().sum()\n",
    "            iou = (intersection + eps) / (union + eps)\n",
    "            iou_per_class[cls].append(iou)\n",
    "\n",
    "    # média por classe\n",
    "    class_ious = [\n",
    "        torch.stack(iou_list).mean()\n",
    "        for iou_list in iou_per_class\n",
    "        if len(iou_list) > 0\n",
    "    ]\n",
    "\n",
    "    if not class_ious:\n",
    "        return 0.0\n",
    "\n",
    "    return torch.stack(class_ious).mean().item()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e570e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "\n",
    "    model         = None\n",
    "    criterion     = None\n",
    "    optimizer     = None\n",
    "    scheduler     = None\n",
    "    learning_rate = None\n",
    "    \n",
    "    #Essa classe treina apenas segmentacao com 1 classe\n",
    "    #Se necessario mais, usar SemanticTrainer\n",
    "    num_classes   = 2\n",
    "\n",
    "    def __init__(self, model_filename=None, model_dir=None, info={}, save_xlsx=False):\n",
    "\n",
    "        if save_xlsx:\n",
    "            if model_filename is None:\n",
    "                raise Exception(\"model_filename é obrigatório ao com save_xlsx == True\")\n",
    "        self.save_xlsx = save_xlsx\n",
    "\n",
    "        #salva o nome e diretorio do modelo\n",
    "        self.model_filename = model_filename\n",
    "        if model_dir is None:\n",
    "            model_dir = model_filename\n",
    "        self.model_dir = model_dir\n",
    "\n",
    "        #se pelo menos o nome do modelo for passado\n",
    "        if self.model_filename is not None:\n",
    "            self.model_file_dir = self.model_dir + \"/\" + self.model_filename\n",
    "        else:\n",
    "            self.model_file_dir = None\n",
    "\n",
    "\n",
    "        #informacoes extra a serem salvas no xslx\n",
    "        self.info = info\n",
    "        #index da imagem sample que sera usada\n",
    "        #para salvar o output durante o treino\n",
    "        self.sample_img_fixed_index = 0\n",
    "\n",
    "    def create_criterion(self):\n",
    "        self.info['loss_function'] = 'BCEWithLogitsLoss'\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    def create_scheduler(self, patience=10, factor=0.5, mode='max'):\n",
    "        self.info['scheduler'] = \"ReduceLROnPlateau(optimizer, mode='max', patience=10, factor=0.5, verbose=True)\"\n",
    "        self.scheduler = ReduceLROnPlateau(self.optimizer, \n",
    "                                      mode=mode, \n",
    "                                      patience=patience, \n",
    "                                      factor=factor)\n",
    "        \n",
    "        \n",
    "\n",
    "    def create_optimizer(self):\n",
    "        self.info['optimizer'] = f\"optim.Adam(self.model.parameters(), lr={self.learning_rate})\"\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "\n",
    "\n",
    "    def get_model_output(self,images):\n",
    "        return self.model(images)\n",
    "        \n",
    "    \n",
    "    def train_loop(self, images, masks, epoch):\n",
    "        outputs     = self.get_model_output(images)\n",
    "\n",
    "        outputs_s   = outputs.squeeze(1)\n",
    "        masks_s     = masks.squeeze(1).float()\n",
    "\n",
    "        loss    = self.criterion(outputs_s, masks_s)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        train_loss = loss.item() * images.size(0)\n",
    "\n",
    "        return train_loss\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    def val_loop(self, images, masks):\n",
    "        outputs     = self.get_model_output(images)\n",
    "\n",
    "        loss        = self.criterion(outputs, masks)\n",
    "        val_loss    = loss.item() * images.size(0)\n",
    "\n",
    "\n",
    "        #faz o threshold\n",
    "        preds = torch.sigmoid(outputs)\n",
    "        preds = (preds > 0.5).long()\n",
    "        masks = masks.long()\n",
    "\n",
    "\n",
    "        #computa as metricas\n",
    "        dice, mIoU, precision, recall, q = compute_segmentation_metrics(preds, masks, num_classes=self.num_classes)\n",
    "        IoU = compute_iou(preds, masks, num_classes=self.num_classes)\n",
    "\n",
    "        val_dice      = dice      * images.size(0)\n",
    "        val_mIoU      = mIoU      * images.size(0)\n",
    "        val_IoU       = IoU       * images.size(0)\n",
    "        val_precision = precision * images.size(0)\n",
    "        val_recall    = recall    * images.size(0)\n",
    "        val_q         = q         * images.size(0)\n",
    "\n",
    "        return val_loss, val_dice, val_mIoU, val_IoU, val_precision, val_recall, val_q\n",
    "    \n",
    "\n",
    "\n",
    "    def update_history(self, history, train_loss=None, loss=None, dice=None, miou=None,\n",
    "                   iou=None, precision=None, recall=None, q=None,\n",
    "                   elapsed_time=None, images_per_sec=None, started=None):\n",
    "        if train_loss is not None:\n",
    "            history[\"train_loss\"].append(train_loss)\n",
    "        if loss is not None:\n",
    "            history[\"loss\"].append(loss)\n",
    "        if dice is not None:\n",
    "            history[\"dice\"].append(dice)\n",
    "        if miou is not None:\n",
    "            history[\"miou\"].append(miou)\n",
    "        if iou is not None:\n",
    "            history[\"iou\"].append(iou)\n",
    "        if precision is not None:\n",
    "            history[\"precision\"].append(precision)\n",
    "        if recall is not None:\n",
    "            history[\"recall\"].append(recall)\n",
    "        if q is not None:\n",
    "            history[\"q\"].append(q)\n",
    "        if elapsed_time is not None:\n",
    "            history[\"elapsed_time\"].append(elapsed_time)\n",
    "        if images_per_sec is not None:\n",
    "            history[\"images_per_sec\"].append(images_per_sec)\n",
    "        if started is not None:\n",
    "            history[\"started\"].append(started)\n",
    "\n",
    "\n",
    "\n",
    "    def train(self, model, \n",
    "                    train_loader, \n",
    "                    val_loader,\n",
    "                    test_loader, \n",
    "                    num_epochs=50, \n",
    "                    #salva o modelo a cada\n",
    "                    save_every=None,\n",
    "                    #imprime o andamento a cada\n",
    "                    print_every=None,\n",
    "                    #continua o treinamento de onde parou\n",
    "                    continue_from_last=False,\n",
    "                    #salva a saida da rede a cada\n",
    "                    save_outputs_every=None,\n",
    "                    #verbose==1 imprime o treinamento na mesma linha\n",
    "                    verbose=3,\n",
    "                    learning_rate=1e-4,\n",
    "                    # apos essa quantidade de epocas o treino\n",
    "                    # se a acuracia diminuir o treino ira voltar para o -best\n",
    "                    #e tentar novamente, até que aumente ou exceda a quantidade de tentativas\n",
    "                    scheduler_patience=10,\n",
    "                    early_stop_patience=20\n",
    "                    ):\n",
    "\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        device = self.get_device()\n",
    "\n",
    "        self.learning_rate  = learning_rate\n",
    "        self.model          = model\n",
    "        start_epoch         = 0\n",
    "        best_score          = -1.0\n",
    "        best_stats          = \"\"\n",
    "        start_time          = time.time()\n",
    "        started             = False\n",
    "        best_path           = self.model_file_dir.replace('.pth', '-best.pth')\n",
    "        last_path           = self.model_file_dir.replace('.pth', '-last.pth')\n",
    "        batch_size          = train_loader.batch_size\n",
    "\n",
    "        trainable_parameters = count_trainable_parameters(model)\n",
    "        print(\"trainable_parameters:\", trainable_parameters)\n",
    "        self.info['dataset_name']         = train_loader.dataset.__module__\n",
    "        self.info['dataset_batch_size']   = batch_size\n",
    "        self.info['trainable_parameters'] = trainable_parameters\n",
    "        images, labels = next(iter(train_loader))\n",
    "        self.info['dataset_resolution']   = f\"{images.shape[2]} x {images.shape[3]}\"\n",
    "        \n",
    "\n",
    "        self.val_history = {\n",
    "            \"train_loss\":     [],\n",
    "            \"loss\":           [],\n",
    "            \"dice\":           [],\n",
    "            \"miou\":           [],\n",
    "            \"iou\":            [],\n",
    "            \"precision\":      [],\n",
    "            \"recall\":         [],\n",
    "            \"q\":              [],\n",
    "            \"elapsed_time\":   [],\n",
    "            \"images_per_sec\": [],\n",
    "            \"started\":        [],\n",
    "        }\n",
    "        self.test_history = {k: [] for k in self.val_history}\n",
    "        \n",
    "\n",
    "        #imprime tudo na mesma linha\n",
    "        tqdm_disable = print_every!=None\n",
    "        print_end    = '\\r\\n'\n",
    "        if verbose == 1:\n",
    "            print_end    = '\\r'\n",
    "            tqdm_disable = True\n",
    "\n",
    "\n",
    "        \n",
    "        #se o nome do modelo foi passado\n",
    "        if self.model_filename is not None:\n",
    "            #cria os diretorios\n",
    "            os.makedirs(self.model_dir, exist_ok=True)\n",
    "\n",
    "            #primeiro, verifica se o modelo final, treinado ja existe\n",
    "            if os.path.exists(self.model_file_dir):\n",
    "                #se ja existir, carrega e retorna\n",
    "                print(\"Modelo treinado já existe.\")\n",
    "                self.load_model(self.model_file_dir)\n",
    "                self.print_last_history_stats()\n",
    "                return model\n",
    "            #se nao existir e for uma continuacao do treinamento\n",
    "            elif continue_from_last == True:\n",
    "                #continua a partir do -last\n",
    "                if os.path.exists(last_path):\n",
    "                    _, _, start_epoch, start_time = self.load_model(last_path)\n",
    "                    print(f\"Continuando do modelo salvo: {last_path}\")\n",
    "                    print(f\"start_epoch: {start_epoch}, start_time: {start_time}\")\n",
    "                    if start_epoch >= num_epochs:\n",
    "                        self.print_last_history_stats()\n",
    "                        return self.model\n",
    "            \n",
    "\n",
    "\n",
    "        model.to(device)\n",
    "        self.create_criterion()\n",
    "        self.create_optimizer()\n",
    "        self.create_scheduler(patience=scheduler_patience)\n",
    "        early_stopper = EarlyStopping(patience=early_stop_patience, mode='max')\n",
    "    \n",
    "\n",
    "        # Se a opcao de salvar output a cada epoca for enviado\n",
    "        # Pega uma imagem fixa fora do loop de treinamento\n",
    "        if save_outputs_every is not None:\n",
    "            sample_imgs, sample_masks = next(iter(val_loader))\n",
    "            self.sample_img_fixed  = sample_imgs[0+self.sample_img_fixed_index:self.sample_img_fixed_index+1].to(device)\n",
    "            self.sample_mask_fixed = sample_masks[0+self.sample_img_fixed_index:self.sample_img_fixed_index+1]\n",
    "        \n",
    "\n",
    "        ## Treinamento\n",
    "        epoch = start_epoch\n",
    "        for epoch in range(start_epoch, num_epochs):\n",
    "            \n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            for images, masks in tqdm(train_loader, desc=f\"Treinando Epoch {epoch+1}\", disable=tqdm_disable):\n",
    "                images = images.to(device)\n",
    "                masks  = masks.to(device)\n",
    "                ## loop de treino\n",
    "                train_loss += self.train_loop(images, masks, epoch)\n",
    "\n",
    "            avg_train_loss = train_loss / len(train_loader.dataset)\n",
    "            \n",
    "\n",
    "            ## Validação\n",
    "            model.eval()\n",
    "            val_loss        = 0.0\n",
    "            val_dice        = 0.0\n",
    "            val_mIoU        = 0.0\n",
    "            val_IoU         = 0.0\n",
    "            val_precision   = 0.0\n",
    "            val_recall      = 0.0\n",
    "            val_q           = 0.0\n",
    "            with torch.no_grad():\n",
    "                for images, masks in val_loader:\n",
    "                    images = images.to(device)\n",
    "                    masks  = masks.to(device)\n",
    "                    #loop de validacao\n",
    "                    loss, dice, mIoU, IoU, precision, recall, q = self.val_loop(images, masks)\n",
    "                    \n",
    "\n",
    "                    val_loss      += loss\n",
    "                    val_dice      += dice\n",
    "                    val_mIoU      += mIoU\n",
    "                    val_IoU       += IoU\n",
    "                    val_precision += precision\n",
    "                    val_recall    += recall\n",
    "                    val_q         += q\n",
    "\n",
    "            avg_val_loss        = val_loss / len(val_loader.dataset)\n",
    "            avg_val_dice        = val_dice / len(val_loader.dataset)\n",
    "            avg_val_mIoU        = val_mIoU / len(val_loader.dataset)\n",
    "            avg_val_IoU         = val_IoU  / len(val_loader.dataset)\n",
    "            avg_val_precision   = val_precision   / len(val_loader.dataset)\n",
    "            avg_val_recall      = val_recall   / len(val_loader.dataset)\n",
    "            avg_val_q           = val_q    / len(val_loader.dataset)\n",
    "\n",
    "\n",
    "            ## Test\n",
    "            test_loss        = 0.0\n",
    "            test_dice        = 0.0\n",
    "            test_mIoU        = 0.0\n",
    "            test_IoU         = 0.0\n",
    "            test_precision   = 0.0\n",
    "            test_recall      = 0.0\n",
    "            test_q           = 0.0\n",
    "            with torch.no_grad():\n",
    "                for images, masks in test_loader:\n",
    "                    images = images.to(device)\n",
    "                    masks  = masks.to(device)\n",
    "                    loss, dice, mIoU, IoU, precision, recall, q = self.val_loop(images, masks)\n",
    "                    \n",
    "                    test_loss      += loss\n",
    "                    test_dice      += dice\n",
    "                    test_mIoU      += mIoU\n",
    "                    test_IoU       += IoU\n",
    "                    test_precision += precision\n",
    "                    test_recall    += recall\n",
    "                    test_q         += q\n",
    "\n",
    "            avg_test_loss        = test_loss / len(test_loader.dataset)\n",
    "            avg_test_dice        = test_dice / len(test_loader.dataset)\n",
    "            avg_test_mIoU        = test_mIoU / len(test_loader.dataset)\n",
    "            avg_test_IoU         = test_IoU  / len(test_loader.dataset)\n",
    "            avg_test_precision   = test_precision   / len(test_loader.dataset)\n",
    "            avg_test_recall      = test_recall   / len(test_loader.dataset)\n",
    "            avg_test_q           = test_q    / len(test_loader.dataset)\n",
    "\n",
    "            elapsed     = time.time() - start_time\n",
    "            elapsed_str = time.strftime(\"%H:%M:%S\", time.gmtime(elapsed))\n",
    "            current_lr  = self.optimizer.param_groups[0]['lr']\n",
    "            stats = (f\"Epoch [{epoch+1}/{num_epochs}] - \" \n",
    "                    f\"Loss: {avg_train_loss:.4f} Val Loss: {avg_val_loss:.4f} \" \n",
    "                    f\"Dice: {avg_val_dice:.4f} mIoU: {avg_val_mIoU:.4f} IoU: {avg_val_IoU:.4f} \" \n",
    "                    f\"Precision: {avg_val_precision:.4f} \" \n",
    "                    f\"Recall: {avg_val_recall:.4f} Q: {avg_val_q:.4f} \" \n",
    "                    f\"Tempo total: {elapsed_str} LR:{current_lr:.6f}\")\n",
    "\n",
    "\n",
    "            if print_every is None:\n",
    "                print(stats,end=print_end)\n",
    "            else:\n",
    "                if (epoch+1) % print_every == 0:\n",
    "                    print(stats,end=print_end)\n",
    "            \n",
    "\n",
    "            images_per_sec = (len(train_loader) * batch_size) / elapsed\n",
    "            \n",
    "            ## Salva a evolucao da rede\n",
    "            self.update_history(\n",
    "                self.val_history,\n",
    "                train_loss=avg_train_loss,\n",
    "                loss=avg_val_loss,\n",
    "                dice=avg_val_dice,\n",
    "                miou=avg_val_mIoU,\n",
    "                iou=avg_val_IoU,\n",
    "                precision=avg_val_precision,\n",
    "                recall=avg_val_recall,\n",
    "                q=avg_val_q,\n",
    "                elapsed_time=elapsed_str,\n",
    "                images_per_sec=images_per_sec,\n",
    "                started=('started' if not started else '')\n",
    "            )\n",
    "            self.update_history(\n",
    "                self.test_history,\n",
    "                train_loss=avg_train_loss,\n",
    "                loss=avg_test_loss,\n",
    "                dice=avg_test_dice,\n",
    "                miou=avg_test_mIoU,\n",
    "                iou=avg_test_IoU,\n",
    "                precision=avg_test_precision,\n",
    "                recall=avg_test_recall,\n",
    "                q=avg_test_q,\n",
    "                elapsed_time=elapsed_str,\n",
    "                images_per_sec=images_per_sec,\n",
    "                started=('started' if not started else '')\n",
    "            )\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "            started = True\n",
    "\n",
    "\n",
    "            # O avg_val_dice será observado para o scheduler e early_stopper\n",
    "\n",
    "            # reduz o learning rate caso o score nao melhore\n",
    "            self.scheduler.step(avg_val_dice)\n",
    "\n",
    "            # para o treinamento caso nao melhore em X epocas\n",
    "            early_stopper.step(avg_val_dice)\n",
    "            if early_stopper.early_stop:\n",
    "                print(f\"Parando na época {epoch+1} por early stopping.\")\n",
    "                break\n",
    "\n",
    "            ## Salva o melhor modelo ate o momento\n",
    "            if avg_val_dice > best_score:\n",
    "                best_score = avg_val_dice\n",
    "                \n",
    "                if self.model_file_dir is not None:\n",
    "                    #salva o modelo na melhor epoca\n",
    "                    self.save_model(best_path, epoch, best_score)\n",
    "                    current_lr  = self.optimizer.param_groups[0]['lr']\n",
    "                    best_stats = (f\"Epoch [{epoch+1}/{num_epochs}] - \" \n",
    "                                f\"Loss: {avg_train_loss:.4f} Val Loss: {avg_val_loss:.4f} \" \n",
    "                                f\"Dice: {avg_val_dice:.4f} mIoU: {avg_val_mIoU:.4f} IoU: {avg_val_IoU:.4f} \" \n",
    "                                f\"Precision: {avg_val_precision:.4f} \" \n",
    "                                f\"Recall: {avg_val_recall:.4f} Q: {avg_val_q:.4f} \" \n",
    "                                f\"Tempo total: {elapsed_str} LR:{current_lr:.6f}\")\n",
    "                    if print_every is None and verbose > 1:\n",
    "                        print(\"✔ Melhor modelo salvo:\", best_stats, end=print_end)\n",
    "                    #salva o excel ate o momento atual\n",
    "                    if self.save_xlsx:\n",
    "                        self.do_save_xlsx()\n",
    "            \n",
    "                \n",
    "\n",
    "\n",
    "            \n",
    "            #Se for para salvar a evolucao do predict da rede\n",
    "            ## Salvar saída da rede em imagem\n",
    "            if save_outputs_every is not None and (epoch + 1) % save_outputs_every == 0:\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    fig, axs = self._save_output(epoch=epoch+1)\n",
    "                    plt.tight_layout()\n",
    "                    outdir = os.path.join(self.model_dir, 'outputs') if self.model_dir else 'outputs'\n",
    "                    os.makedirs(outdir, exist_ok=True)\n",
    "                    plt.savefig(os.path.join(outdir, f\"{epoch+1:03d}.png\"))\n",
    "                    plt.close()\n",
    "\n",
    "            if save_every is not None and (epoch + 1) % save_every == 0:\n",
    "                last_model_file_dir = self.model_file_dir.replace('.pth','-last.pth')\n",
    "                self.save_model(last_model_file_dir, epoch, best_score)\n",
    "                self.do_save_xlsx()\n",
    "                if verbose > 1:\n",
    "                    print(\"Saved last as\", last_model_file_dir, end=print_end)\n",
    "\n",
    "\n",
    "        \n",
    "        last_stats = (f\"Epoch [{epoch+1}/{num_epochs}] - \" \n",
    "                    f\"Loss: {avg_train_loss:.4f} Val Loss: {avg_val_loss:.4f} \" \n",
    "                    f\"Dice: {avg_val_dice:.4f} mIoU: {avg_val_mIoU:.4f} IoU: {avg_val_IoU:.4f} \" \n",
    "                    f\"Precision: {avg_val_precision:.4f} \" \n",
    "                    f\"Recall: {avg_val_recall:.4f} Q: {avg_val_q:.4f} \" \n",
    "                    f\"Tempo total: {elapsed_str} LR:{current_lr:.6f}\")\n",
    "        \n",
    "\n",
    "\n",
    "        #calcula o FPS do modelo\n",
    "        self.info['FPS'], self.info['time_per_image'] = measure_inference_speed(self.model, val_loader)\n",
    "            \n",
    "        print(\"\")\n",
    "        if best_stats:\n",
    "            print(\"Melhor modelo:\\r\\n\", best_stats)\n",
    "        print(\"Ultimo modelo:\\r\\n\", last_stats + ' FPS:',self.info['FPS'])\n",
    "\n",
    "\n",
    "        if self.model_file_dir is not None:\n",
    "            self.save_model(self.model_file_dir, epoch, best_score)\n",
    "            print(\"Saved as\", self.model_file_dir)\n",
    "\n",
    "        \n",
    "        if self.save_xlsx:\n",
    "            # Escreve o arquivo excel com o history\n",
    "            self.do_save_xlsx()\n",
    "\n",
    "        #beep win\n",
    "        #os.system('powershell.exe -Command \"[console]::beep(600,200); [console]::beep(600,200);\"')\n",
    "        #linux\n",
    "        os.system('play -nq -t alsa synth 0.2 sine 600; play -nq -t alsa synth 0.2 sine 600')\n",
    "        return model\n",
    "\n",
    "\n",
    "    def print_last_history_stats(self):\n",
    "        #INFO\n",
    "        last_stats = \"\"\n",
    "        keys = list(self.info.keys())\n",
    "        for key in keys:\n",
    "            value = self.info[key]\n",
    "            last_stats += f\"{key}:{value} \"\n",
    "        print(last_stats)\n",
    "        #History\n",
    "        last_stats = \"\"\n",
    "        keys = list(self.val_history.keys())\n",
    "        for key in keys:\n",
    "            value = self.val_history[key][-1]\n",
    "            last_stats += f\"{key}:{value} \"\n",
    "        print(last_stats)\n",
    "\n",
    "\n",
    "\n",
    "    def _save_output(self,epoch=None):\n",
    "        with torch.no_grad():\n",
    "            output = self.get_model_output(self.sample_img_fixed)\n",
    "\n",
    "            # Aplicar sigmoid e limiar\n",
    "            out_sigmoid = torch.sigmoid(output[0])\n",
    "            out_thresh = (out_sigmoid > 0.5).float()\n",
    "            out_thresh_np = out_thresh.cpu().squeeze().numpy()\n",
    "            sample_mask_fixed_s = self.sample_mask_fixed.squeeze().cpu().numpy()\n",
    "\n",
    "            # Inicializar imagem RGB de saída com zeros (preto = true negative)\n",
    "            h, w = sample_mask_fixed_s.shape\n",
    "            diff_img = np.zeros((h, w, 3), dtype=np.float32)\n",
    "\n",
    "            # Máscaras para os diferentes tipos de pixel\n",
    "            tp = (out_thresh_np == 1) & (sample_mask_fixed_s == 1)\n",
    "            fn = (out_thresh_np == 0) & (sample_mask_fixed_s == 1)\n",
    "            fp = (out_thresh_np == 1) & (sample_mask_fixed_s == 0)\n",
    "\n",
    "            # Aplicar cores\n",
    "            diff_img[tp] = [1, 1, 1]       # Branco\n",
    "            diff_img[fn] = [1, 0.5, 0]     # Laranja\n",
    "            diff_img[fp] = [1, 0, 0]       # Vermelho\n",
    "\n",
    "            # Criar a figura\n",
    "            fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
    "            axs[0].imshow(sample_mask_fixed_s, cmap='gray')\n",
    "            axs[0].set_title(\"Ground Truth\")\n",
    "            axs[0].axis('off')\n",
    "\n",
    "            axs[1].imshow(out_thresh_np, cmap='gray')\n",
    "            axs[1].set_title(\"Predição\")\n",
    "            axs[1].axis('off')\n",
    "\n",
    "            axs[2].imshow(diff_img)\n",
    "            axs[2].set_title(\"Diferença (TP=branco, FN=laranja, FP=vermelho)\")\n",
    "            axs[2].axis('off')\n",
    "\n",
    "            suptitle = self.model_filename.replace('.pth', '')\n",
    "            if epoch is not None:\n",
    "                suptitle += f\" epoch:{epoch}\"\n",
    "\n",
    "            fig.suptitle(suptitle, fontsize=14)\n",
    "            return fig, axs\n",
    "\n",
    "\n",
    "    \n",
    "    def save_sample_output(self, data_loader, samples=[0]):\n",
    "\n",
    "        if self.model is None:\n",
    "            raise Exception(\"O modelo ainda não foi carregado, use trainer.load_model(model=model) passando o objeto do modelo.\")\n",
    "\n",
    "        #define qual sera a amostra\n",
    "        device                      = next(self.model.parameters()).device\n",
    "        if type(samples) == int:\n",
    "            samples = [samples]\n",
    "\n",
    "        for sample in samples:\n",
    "            sample_imgs, sample_masks   = next(iter(data_loader))\n",
    "            self.sample_img_fixed       = sample_imgs[0+sample:sample+1].to(device)\n",
    "            self.sample_mask_fixed      = sample_masks[0+sample:sample+1]\n",
    "            #gera o output\n",
    "            fig, axs = self._save_output()\n",
    "            #salva a amostra\n",
    "            plt.tight_layout()\n",
    "            outdir = os.path.join(self.model_dir, 'outputs') if self.model_dir else 'outputs'\n",
    "            os.makedirs(outdir, exist_ok=True)\n",
    "            fig_path = os.path.join(outdir, f\"sample{sample}-{self.model_filename}\").replace('.pth','.png')\n",
    "            plt.savefig(fig_path)\n",
    "            plt.close()\n",
    "            print(fig_path, 'saved.')\n",
    "    \n",
    "\n",
    "\n",
    "    def do_save_xlsx(self):\n",
    "\n",
    "        avg_speed = sum(self.val_history['images_per_sec']) / len(self.val_history['images_per_sec'])\n",
    "        self.info['training_speed_img_per_sec'] = round(avg_speed, 2)\n",
    "\n",
    "\n",
    "        hist_name = self.model_file_dir.replace('.pth', '.xlsx')\n",
    "        df_val_history = pd.DataFrame(self.val_history)\n",
    "        df_val_history.insert(0, 'epoch', range(1, len(df_val_history)+1))\n",
    "        df_val_history['epoch'] = df_val_history['epoch'].astype(str)\n",
    "\n",
    "\n",
    "        df_test_history = pd.DataFrame(self.test_history)\n",
    "        df_test_history.insert(0, 'epoch', range(1, len(df_test_history)+1))\n",
    "        df_test_history['epoch'] = df_test_history['epoch'].astype(str)\n",
    "\n",
    "\n",
    "        df_info = pd.DataFrame(self.info, index=[0])\n",
    "        with pd.ExcelWriter(hist_name, engine='xlsxwriter') as writer:\n",
    "            df_val_history.to_excel(writer, sheet_name='val_history', index=False, float_format=\"%.4f\")\n",
    "            df_test_history.to_excel(writer, sheet_name='test_history', index=False, float_format=\"%.4f\")\n",
    "            df_info.to_excel(writer, sheet_name='model_info', index=False, float_format=\"%.4f\")\n",
    "\n",
    "            workbook  = writer.book\n",
    "            worksheet = writer.sheets['val_history']\n",
    "\n",
    "            chart = workbook.add_chart({'type': 'line'})\n",
    "\n",
    "            # A coluna 'epoch' agora está na coluna 0\n",
    "            # Supondo que 'val_dice' esteja na coluna 5 e 'val_IoU' na 6 (ou ajuste isso dinamicamente)\n",
    "            col_dice = df_val_history.columns.get_loc('dice')\n",
    "            col_iou  = df_val_history.columns.get_loc('miou')\n",
    "\n",
    "            chart.add_series({\n",
    "                'name':       'dice',\n",
    "                'categories': ['val_history', 1, 0, len(df_val_history), 0],  # coluna 0 = epoch\n",
    "                'values':     ['val_history', 1, col_dice, len(df_val_history), col_dice],\n",
    "            })\n",
    "            chart.add_series({\n",
    "                'name':       'mIoU',\n",
    "                'categories': ['val_history', 1, 0, len(df_val_history), 0],\n",
    "                'values':     ['val_history', 1, col_iou, len(df_val_history), col_iou],\n",
    "            })\n",
    "\n",
    "            chart.set_title({'name': 'Treinamento'})\n",
    "\n",
    "            chart.set_x_axis({\n",
    "                'name': 'Época',\n",
    "                'interval_unit': 10,\n",
    "                'num_font': {'rotation': -45},\n",
    "            })\n",
    "            chart.set_y_axis({'name': 'Valor'})\n",
    "\n",
    "            worksheet.insert_chart('K2', chart)\n",
    "\n",
    "    \n",
    "    \n",
    "    def load_xlsx_history(self):\n",
    "        hist_name = self.model_file_dir.replace('.pth', '.xlsx').replace('-best','')\n",
    "        \n",
    "        # Lê todas as planilhas do arquivo\n",
    "        xls = pd.read_excel(hist_name, sheet_name=None)\n",
    "\n",
    "        # Recupera o DataFrame de histórico e converte para lista de dicionários\n",
    "        df_val_history   = xls['val_history']\n",
    "        last_epoch   = int(df_val_history['epoch'].iloc[-1])\n",
    "        self.val_history = df_val_history.drop(columns=['epoch']).to_dict(orient='list')\n",
    "\n",
    "\n",
    "        df_test_history   = xls['test_history']\n",
    "        self.test_history = df_test_history.drop(columns=['epoch']).to_dict(orient='list')\n",
    "\n",
    "        # Tempo acumulado\n",
    "        elapsed_str      = df_val_history['elapsed_time'].iloc[-1]\n",
    "        h, m, s          = map(int, elapsed_str.split(':'))\n",
    "        accumulated_time = timedelta(hours=h, minutes=m, seconds=s).total_seconds()\n",
    "        start_time       = time.time() - accumulated_time  # Ajusta para manter contagem acumulada\n",
    "\n",
    "        # Recupera o DataFrame de informações do modelo e converte para dicionário\n",
    "        df_info = xls['model_info']\n",
    "        self.info = df_info.iloc[0].to_dict()\n",
    "        return last_epoch, start_time\n",
    "\n",
    "    def load_model(self, model_file_dir, model=None, load_xlsx=True, load_scheduler=False):\n",
    "        #se o modelo for passado\n",
    "        if model is not None:\n",
    "            #self.model recebe o novo modelo\n",
    "            self.model = model\n",
    "        #se o modelo a ser carregado nao foi passado\n",
    "        if self.model is None:\n",
    "            raise Exception(\"Voce precisa passar o objeto do modelo no parametro 'model'\")\n",
    "        \n",
    "        if self.optimizer is None:\n",
    "            self.create_optimizer()\n",
    "        if self.scheduler is None:\n",
    "            self.create_scheduler()\n",
    "        \n",
    "        #carrega o modelo do arquivo .pth\n",
    "        checkpoint = torch.load(model_file_dir, weights_only=False)\n",
    "        #recupera os states do arquivo\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        if load_scheduler:\n",
    "            self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        best_score  = checkpoint['best_acc']\n",
    "        epoch       = checkpoint['epoch'] + 1\n",
    "        self.model.to(self.get_device())\n",
    "        print(f\"Modelo carregado: {model_file_dir}\")\n",
    "        if load_xlsx:\n",
    "            start_epoch, start_time = self.load_xlsx_history()\n",
    "            return best_score, epoch, start_epoch, start_time\n",
    "        return best_score, epoch\n",
    "    \n",
    "    def save_model(self, path, epoch, best_score):\n",
    "        torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': self.model.state_dict(),\n",
    "                'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                'scheduler_state_dict': self.scheduler.state_dict(),\n",
    "                'best_acc': best_score\n",
    "                }, path)\n",
    "    \n",
    "    def get_device(self):\n",
    "        return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
